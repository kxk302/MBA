{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MBA",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kxk302/MBA/blob/main/MBA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JDt_5RMdjL7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0bkibi4dy-V"
      },
      "source": [
        "!ls '/content/gdrive/MyDrive/Colab Notebooks/MBA_files'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8BTJgr3VIiP"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "funclass_dict = {\"1\":\"Silent\", \"2\":\"Nonsense\", \"3\":\"Misense\", \"4\":\"None\"}\n",
        "af_dict = {\"1\":\"AF < 0.20\", \"2\": \"0.80 > AF >= 0.20\", \"3\":\"AF >= 0.80\"}\n",
        "\n",
        "def to_str_each(items):\n",
        "  items_str = \"\"\n",
        "  for item in items:\n",
        "    item_str = \"(\" + item[0:-2:1] + \", \" + funclass_dict.get(item[-2:-1:1]) + \", \" + af_dict.get(item[-1]) + \") & \"\n",
        "    items_str += item_str \n",
        "  return items_str[:-3]\n",
        "\n",
        "# Convert series of antecedents/consequents to human readable \n",
        "def to_str(ser):    \n",
        "  # Cast to string\n",
        "  ser = ser.astype(str)  \n",
        "\n",
        "  # Get rid of unnecessary characters prior to list of (position + funclass + af) numbers\n",
        "  ser = ser.str.slice(12,-3,1)  \n",
        "\n",
        "  # Get rid of single quotes\n",
        "  ser = ser.replace('\\'', '', regex=True)\n",
        "\n",
        "  ser = ser.str.split(pat=\",\")\n",
        "\n",
        "  return ser.apply(to_str_each)\n",
        "\n",
        "def add_readable_rules(df_in):\n",
        "  # Empty data frame\n",
        "  if df_in is None or df_in.shape[0] == 0:\n",
        "    return df_in\n",
        "\n",
        "  df = df_in.copy()\n",
        "\n",
        "  antecedents_str = to_str(df['antecedents'])\n",
        "  consequents_str = to_str(df['consequents'])\n",
        "\n",
        "  readable_rule = \"(\" + antecedents_str + \") => (\" + consequents_str + \")\"\n",
        "  df.insert(2,'readable_rule', readable_rule)\n",
        "\n",
        "  return df\n",
        "\n",
        "def filter_on_position_probability(df_in, start_prob=None, end_prob=None):\n",
        "    if df_in is None or df_in.shape[0] == 0:\n",
        "      return df_in\n",
        "\n",
        "    if start_prob is None and end_prob is None:\n",
        "      return df_in\n",
        "\n",
        "    # Only consider rows where probability of Position being present in the Samples is >= start_prob and <= end_prob\n",
        "    num_samples = df_in['Sample'].nunique()\n",
        "    print(\"num_samples: {}\".format(num_samples))\n",
        "\n",
        "    num_positions = df_in['POS'].nunique()\n",
        "    print(\"num_positions: {}\".format(num_positions))\n",
        "   \n",
        "    df = df_in[['Sample', 'POS']].groupby(['POS']).agg(position_prob=('Sample', 'count'))\n",
        "    # Normalize position_prob by dividing it by num_samples. This makes it a proability between 0.0 and 1.0\n",
        "    df['position_prob'] = df['position_prob'] / num_samples   \n",
        "\n",
        "    df_sorted = df.sort_values(by = 'position_prob')\n",
        "    print(df_sorted.head())\n",
        "    print(df_sorted.tail())\n",
        "  \n",
        "    if start_prob is not None:\n",
        "      df = df[df.position_prob >= start_prob]\n",
        "\n",
        "    if end_prob is not None:\n",
        "      df = df[df.position_prob <= end_prob]\n",
        "    \n",
        "    ret_val = pd.merge(df_in, df, on='POS')\n",
        "\n",
        "    df_sorted = ret_val.sort_values(by = 'position_prob')[['POS', 'position_prob']]\n",
        "    print(df_sorted.head())\n",
        "    print(df_sorted.tail())\n",
        "\n",
        "    return ret_val\n",
        "\n",
        "def get_position_probability(df_in, position=None):\n",
        "    if df_in is None or df_in.shape[0] == 0:\n",
        "      return df_in\n",
        "\n",
        "    if position is None:\n",
        "      return df_in\n",
        "\n",
        "    num_samples = df_in['Sample'].nunique()\n",
        "    print(\"num_samples: {}\".format(num_samples))\n",
        "\n",
        "    num_positions = df_in['POS'].nunique()\n",
        "    print(\"num_positions: {}\".format(num_positions))\n",
        "   \n",
        "    df = df_in[['Sample', 'POS']].groupby(['POS']).agg(position_prob=('Sample', 'count'))\n",
        "    # Normalize position_prob by dividing it by num_samples. This makes it a proability between 0.0 and 1.0\n",
        "    df['position_prob'] = df['position_prob'] / num_samples\n",
        "\n",
        "    try:      \n",
        "      return df.loc[position,'position_prob']\n",
        "    except KeyError:\n",
        "      return -1\n",
        "\n",
        "def filter_on_column_values(df_in, start_pos=None, end_pos=None, start_af=None, end_af=None, funclass=[]):  \n",
        "  if df_in is None or df_in.shape[0] == 0:\n",
        "    return df_in\n",
        "\n",
        "  df = df_in.copy()\n",
        "\n",
        "  # Replace \".\" with \"NONE\" in FUNCLASS column. They both represent \"Non-coding\" variant\n",
        "  df[\"FUNCLASS\"] = df[\"FUNCLASS\"].replace('.', 'NONE')\n",
        "\n",
        "  # Filter in_file rows\n",
        "  if start_pos is not None:\n",
        "    df = df[df.POS >= start_pos]    \n",
        "  if end_pos is not None:\n",
        "    df = df[df.POS <= end_pos]    \n",
        "  if start_af is not None:\n",
        "    df = df[df.AF >= start_af]    \n",
        "  if end_af is not None:\n",
        "    df = df[df.AF <= end_af]    \n",
        "  if len(funclass) > 0:    \n",
        "    df = df[df.FUNCLASS.isin(funclass)]\n",
        "\n",
        "  return df\n",
        "\n",
        "# Create a single integer representing a variant at a specific position with a specific allele frequency\n",
        "# Pivot the data so we have all sample variants on a single line\n",
        "#\n",
        "# Extract rows from in_file where\n",
        "# \n",
        "#    POS >= start_pos & POS <= end_pos\n",
        "#        If start_pos = None: POS <= end_pos\n",
        "#        If end_pos = None: POS >= start_pos \n",
        "#\n",
        "#    AF >= start_af & AF <= end_af\n",
        "#        If start_af = None: AF <= end_af\n",
        "#        If end_af = None: AF >= start_af\n",
        "#\n",
        "#    FUNCLASS in funclass (funclass is a list)      \n",
        "#\n",
        "def preprocess_input_file(df_in):\n",
        "  if df_in is None or df_in.shape[0] == 0:\n",
        "    return df_in\n",
        "  \n",
        "  df = df_in.copy()\n",
        "\n",
        "  # Bucket values in FUNCLASS and AF columns. We do not bucket the values in POS column.\n",
        "\n",
        "  # Replace variants in FUNCLASS column with a distinct numeric value\n",
        "  df.loc[df.FUNCLASS == \"NONE\", \"FUNCLASS\"] = 4\n",
        "  df.loc[df.FUNCLASS == \"MISSENSE\", \"FUNCLASS\"] = 3\n",
        "  df.loc[df.FUNCLASS == \"NONSENSE\", \"FUNCLASS\"] = 2 \n",
        "  df.loc[df.FUNCLASS == \"SILENT\", \"FUNCLASS\"] = 1 \n",
        "\n",
        "  # Replace allele frequency in AF column with a distict numeric value\n",
        "  df.loc[df.AF >= 0.80, \"AF\"] = 3\n",
        "  df.loc[(df.AF >= 0.20) & (df.AF < 0.80), \"AF\"] = 2\n",
        "  df.loc[df.AF < 0.20, \"AF\"] = 1\n",
        "\n",
        "  # Convert AF values to integer\n",
        "  df = df.astype({\"AF\": int}) \n",
        "\n",
        "  # Create a new column called 'Label', which is a string concatentation of POS, FUNCLASS, and AF values. \n",
        "  # The idea is to represent each variant + allele frequency + position as a single integer, to be used in MBA \n",
        "  df[\"Label\"] = df[\"POS\"].astype(str) + df[\"FUNCLASS\"].astype(str) + df[\"AF\"].astype(str)\n",
        "\n",
        "  # We do not need POS, FUNCLASS, and AF columns anymore\n",
        "  df = df[[\"Sample\", \"Label\"]]\n",
        "  \n",
        "  # Add a new column called 'Value', prepopulated with 1\n",
        "  df[\"Value\"] = 1\n",
        "\n",
        "  df = pd.pivot_table(df, index=\"Sample\", columns=\"Label\", values=\"Value\")\n",
        "\n",
        "  # Set all data frame nan (not a number) values to 0\n",
        "  df = df.fillna(0)\n",
        "\n",
        "  # Convert all data framevalues to integer\n",
        "  df = df.astype(int) \n",
        "\n",
        "  return df"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VubP1ctVUsc"
      },
      "source": [
        "def get_association_rules(in_file, min_support=0.20, min_confidence=0.80, min_lift=1.0, min_conviction=1.0, max_len=None, start_pos=None, end_pos=None, start_af=None, end_af=None, funclass=[], start_prob=None, end_prob=None):\n",
        "  # Read the input file and pick the needed columns\n",
        "  df_in = pd.read_csv(in_file, sep='\\t')[['Sample', 'POS', 'AF', 'FUNCLASS']]\n",
        "\n",
        "  # Filter on position probability\n",
        "  df_pp = filter_on_position_probability(df_in, start_prob, end_prob)\n",
        "\n",
        "  # Filter on column values\n",
        "  df_cv = filter_on_column_values(df_pp, start_pos, end_pos, start_af, end_af, funclass)\n",
        "\n",
        "  # Preprocess the data frame\n",
        "  df = preprocess_input_file(df_cv)\n",
        "\n",
        "  # Get frequent item sets, with support larger than min_support, using Apriori algorithm\n",
        "  frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True, max_len=max_len)\n",
        "\n",
        "  # Get association rules, with lift larger than min_lift  \n",
        "  rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_lift)\n",
        "\n",
        "  # Filter association rules, keeping rules with confidence larger than min_confidence\n",
        "  rules = rules[ (rules['confidence'] >= min_confidence) & (rules['conviction'] >= min_conviction) ]\n",
        "\n",
        "  return rules"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxoxfSG9fRA3"
      },
      "source": [
        "pd.set_option('max_columns', 10, 'display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "bos_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/bos_by_sample.tsv.gz\", min_support=0.223, min_confidence=0.905, min_lift=2.863, min_conviction=7.0)\n",
        "num_rules = bos_rules.shape[0]\n",
        "print('Boston dataset association rules: ')\n",
        "bos_rules = add_readable_rules(bos_rules)\n",
        "print(bos_rules.head(num_rules))\n",
        "print('\\n\\n')\n",
        "# bos_rules.to_csv('/content/gdrive/MyDrive/Colab Notebooks/MBA_files/bos_0223_0905_2863_7000.csv', sep=',')\n",
        "\n",
        "uke_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/cog_20200917_by_sample.tsv.gz\", min_support=0.21, min_confidence=0.91, min_lift=2.5, min_conviction=7.0)\n",
        "num_rules = uke_rules.shape[0]\n",
        "print('UK early dataset association rules: ')\n",
        "uke_rules = add_readable_rules(uke_rules)\n",
        "print(uke_rules.head(num_rules))\n",
        "print('\\n\\n')\n",
        "# uke_rules.to_csv('/content/gdrive/MyDrive/Colab Notebooks/MBA_files/uke_0210_0910_2500_7000.csv', sep=',')\n",
        "\n",
        "ukl_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/cog_20201120_by_sample.tsv.gz\", min_support=0.203, min_confidence=0.926, min_lift=2.03, min_conviction=7.0)\n",
        "num_rules = ukl_rules.shape[0]\n",
        "print('Uk late dataset association rules: ')\n",
        "ukl_rules = add_readable_rules(ukl_rules)\n",
        "print(ukl_rules.head(num_rules))\n",
        "print('\\n\\n')\n",
        "# ukl_rules.to_csv('/content/gdrive/MyDrive/Colab Notebooks/MBA_files/ukl_0203_0926_2030_7000.csv', sep=',')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy3YlHqEyPGK"
      },
      "source": [
        "# Milad \n",
        "pd.set_option('max_columns', 10, 'display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "bos_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/bos_by_sample.tsv.gz\", min_support=0.005, min_confidence=0.05, min_lift=1.00, min_conviction=1.0, max_len=2, start_pos=21563, end_pos=25384, start_af=0.19, end_af=None, funclass=[\"MISSENSE\", \"NONSENSE\"])\n",
        "num_rules = bos_rules.shape[0]\n",
        "print('Boston dataset association rules: ')\n",
        "bos_rules = add_readable_rules(bos_rules)\n",
        "print(bos_rules.head(num_rules))\n",
        "print('\\n\\n')\n",
        "# bos_rules.to_csv('/content/gdrive/MyDrive/Colab Notebooks/MBA_files/bos_0223_0905_2863_7000.csv', sep=',')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5erF_k0uKLI",
        "outputId": "83e3cae5-1769-4fa0-cf3e-72d6f2e19ab2"
      },
      "source": [
        "# Anton\n",
        "pd.set_option('max_columns', 10, 'display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "bos_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/bos_by_sample.tsv.gz\", min_support=0.050, min_confidence=0.800, min_lift=1.0, min_conviction=1.0, max_len=2, end_af=0.80, start_prob=0.000, end_prob=0.40)\n",
        "num_rules = bos_rules.shape[0]\n",
        "print('Number of rules: {}'.format(num_rules))\n",
        "print('Boston dataset association rules: ')\n",
        "bos_rules = add_readable_rules(bos_rules)\n",
        "print(bos_rules.head(num_rules))\n",
        "print('\\n\\n')\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_samples: 639\n",
            "num_positions: 1013\n",
            "       position_prob\n",
            "POS                 \n",
            "28893       0.001565\n",
            "18546       0.001565\n",
            "28647       0.001565\n",
            "18636       0.001565\n",
            "18714       0.001565\n",
            "       position_prob\n",
            "POS                 \n",
            "25563       0.852895\n",
            "241         0.948357\n",
            "23403       0.949922\n",
            "14408       0.951487\n",
            "3037        0.951487\n",
            "        POS  position_prob\n",
            "5997   5431       0.001565\n",
            "5534  26678       0.001565\n",
            "5533  28699       0.001565\n",
            "5532  29000       0.001565\n",
            "5531  28713       0.001565\n",
            "       POS  position_prob\n",
            "1287  2416       0.392801\n",
            "1288  2416       0.392801\n",
            "1289  2416       0.392801\n",
            "1276  2416       0.392801\n",
            "1448  2416       0.392801\n",
            "Number of rules: 22\n",
            "Boston dataset association rules: \n",
            "    antecedents consequents                                                    readable_rule  antecedent support  consequent support   support  confidence       lift  leverage  conviction\n",
            "25     (953511)   (1375531)     ((9535, Silent, AF < 0.20)) => ((13755, Misense, AF < 0.20))            0.062500            0.089527  0.052365    0.837838   9.358491  0.046769    5.614583\n",
            "26    (1568531)   (1568231)   ((15685, Misense, AF < 0.20)) => ((15682, Misense, AF < 0.20))            0.150338            0.222973  0.146959    0.977528   4.384065  0.113438   34.577703\n",
            "40    (1755611)   (2654231)    ((17556, Silent, AF < 0.20)) => ((26542, Misense, AF < 0.20))            0.077703            0.280405  0.064189    0.826087   2.946045  0.042401    4.137669\n",
            "42    (1755611)   (2654531)    ((17556, Silent, AF < 0.20)) => ((26545, Misense, AF < 0.20))            0.077703            0.363176  0.064189    0.826087   2.274621  0.035969    3.661740\n",
            "55    (2071631)   (2355431)   ((20716, Misense, AF < 0.20)) => ((23554, Misense, AF < 0.20))            0.062500            0.177365  0.052365    0.837838   4.723810  0.041280    5.072917\n",
            "57    (2071631)   (2587841)      ((20716, Misense, AF < 0.20)) => ((25878, None, AF < 0.20))            0.062500            0.283784  0.052365    0.837838   2.952381  0.034628    4.416667\n",
            "59    (2071631)   (2612411)    ((20716, Misense, AF < 0.20)) => ((26124, Silent, AF < 0.20))            0.062500            0.130068  0.050676    0.810811   6.233766  0.042546    4.598214\n",
            "61    (2071631)   (2654231)   ((20716, Misense, AF < 0.20)) => ((26542, Misense, AF < 0.20))            0.062500            0.280405  0.055743    0.891892   3.180723  0.038218    6.656250\n",
            "63    (2071631)   (2654531)   ((20716, Misense, AF < 0.20)) => ((26545, Misense, AF < 0.20))            0.062500            0.363176  0.055743    0.891892   2.455814  0.033045    5.890625\n",
            "64     (953511)   (2071631)     ((9535, Silent, AF < 0.20)) => ((20716, Misense, AF < 0.20))            0.062500            0.062500  0.052365    0.837838  13.405405  0.048459    5.781250\n",
            "65    (2071631)    (953511)     ((20716, Misense, AF < 0.20)) => ((9535, Silent, AF < 0.20))            0.062500            0.062500  0.052365    0.837838  13.405405  0.048459    5.781250\n",
            "81     (953511)   (2355431)     ((9535, Silent, AF < 0.20)) => ((23554, Misense, AF < 0.20))            0.062500            0.177365  0.050676    0.810811   4.571429  0.039590    4.348214\n",
            "85    (2494231)   (2903921)  ((24942, Misense, AF < 0.20)) => ((29039, Nonsense, AF < 0.20))            0.074324            0.358108  0.072635    0.977273   2.728988  0.046019   28.243243\n",
            "92     (660411)   (2587841)        ((6604, Silent, AF < 0.20)) => ((25878, None, AF < 0.20))            0.091216            0.283784  0.076014    0.833333   2.936508  0.050128    4.297297\n",
            "98     (953511)   (2587841)        ((9535, Silent, AF < 0.20)) => ((25878, None, AF < 0.20))            0.062500            0.283784  0.055743    0.891892   3.142857  0.038007    6.625000\n",
            "109    (953511)   (2612411)      ((9535, Silent, AF < 0.20)) => ((26124, Silent, AF < 0.20))            0.062500            0.130068  0.050676    0.810811   6.233766  0.042546    4.598214\n",
            "110   (2643331)    (750731)    ((26433, Misense, AF < 0.20)) => ((7507, Misense, AF < 0.20))            0.057432            0.204392  0.052365    0.911765   4.460865  0.040626    9.016892\n",
            "112   (2654231)   (2654531)   ((26542, Misense, AF < 0.20)) => ((26545, Misense, AF < 0.20))            0.280405            0.363176  0.253378    0.903614   2.488092  0.151542    6.607052\n",
            "121    (953511)   (2654231)     ((9535, Silent, AF < 0.20)) => ((26542, Misense, AF < 0.20))            0.062500            0.280405  0.059122    0.945946   3.373494  0.041596   13.312500\n",
            "131    (953511)   (2654531)     ((9535, Silent, AF < 0.20)) => ((26545, Misense, AF < 0.20))            0.062500            0.363176  0.059122    0.945946   2.604651  0.036423   11.781250\n",
            "139    (576531)    (576631)     ((5765, Misense, AF < 0.20)) => ((5766, Misense, AF < 0.20))            0.077703            0.096284  0.074324    0.956522   9.934401  0.066843   20.785473\n",
            "143    (953511)    (660411)       ((9535, Silent, AF < 0.20)) => ((6604, Silent, AF < 0.20))            0.062500            0.091216  0.052365    0.837838   9.185185  0.046664    5.604167\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEa5yn9JFJDI",
        "outputId": "8c9f195c-cb2d-4e74-e917-12c8094c2274"
      },
      "source": [
        "# Test get_position_probability()\n",
        "\n",
        "pd.set_option('max_columns', 10, 'display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Read the input file and pick the needed columns\n",
        "in_file = \"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/bos_by_sample.tsv.gz\"\n",
        "df_in = pd.read_csv(in_file, sep='\\t')[['Sample', 'POS', 'AF', 'FUNCLASS']]\n",
        "\n",
        "position=21\n",
        "position_prob = get_position_probability(df_in, position=position)\n",
        "print(\"position: {}, position_prob: {:.4f}\".format(position, position_prob))\n",
        "\n",
        "position=30\n",
        "position_prob = get_position_probability(df_in, position=position)\n",
        "print(\"position: {}, position_prob: {:.4f}\".format(position, position_prob))\n",
        "\n",
        "position=29806\n",
        "position_prob = get_position_probability(df_in, position=position)\n",
        "print(\"position: {}, position_prob: {:.4f}\".format(position, position_prob))\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_samples: 639\n",
            "num_positions: 1013\n",
            "position: 21, position_prob: 0.0016\n",
            "num_samples: 639\n",
            "num_positions: 1013\n",
            "position: 30, position_prob: -1.0000\n",
            "num_samples: 639\n",
            "num_positions: 1013\n",
            "position: 29806, position_prob: 0.0078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ASKXDBeOsr"
      },
      "source": [
        "---\n",
        "**MBA parameter**s \n",
        "\n",
        "1.   **bos_rules**: *support*=0.223, *confidence*=0.905, *lift*=2.863, *conviction*=7.000\n",
        "2.   **uke_rules**: *support*=0.210, *confidence*=0.910, *lift*=2.500, conviction *italicized text*=7.000\n",
        "3.   **ukl_rules**: *support*=0.203, *confidence*=0.926, *lift*=2.030, *conviction*=7.000\n",
        "---\n",
        "The last digit of an entry is Allele Frequency (**AF**)\n",
        "\n",
        "*   **3**: $>=$ 0.80    \n",
        "*   **2**: $>=$ 0.20 and $<$ 0.80\n",
        "*   **1**: $<$ 0.20\n",
        "---\n",
        "The digit before the last is **Funclass**\n",
        "\n",
        "*  **4**: None\n",
        "*  **3**: Missense\n",
        "*  **2**: Nonsense\n",
        "*  **1**: Silent\n",
        "---\n",
        "**Boston association rules** (12 rules)\n",
        "\n",
        "**Antecedent** entries\n",
        "\n",
        "* 3037**13**  (5 times)\n",
        "* 14408**33** (5 times)\n",
        "* 23403**33** (5 times)\n",
        "* 26542**31** (All 12)\n",
        "\n",
        "**Consequent** entries\n",
        "\n",
        "* 3037**13** (5 times)\n",
        "* 14408**33** (5 times)\n",
        "* 23403**33** (5 times)\n",
        "* 26545**31** (All 12)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XszXqioqokmE"
      },
      "source": [
        "---\n",
        "**UK early association rules** (10 rules)\n",
        "\n",
        "**Antecedent** entries\n",
        "\n",
        "* 241**43**   (9 times)\n",
        "* 14408**33** (3 times)\n",
        "* 23403**33** (4 times)\n",
        "* 28881**32** (All 10)\n",
        "\n",
        "**Consequent** entries\n",
        "\n",
        "* 3037**12**  (All 10)\n",
        "* 14408**33** (3 times)\n",
        "* 23403**33** (3 times)\n",
        "* 28883**33** (All 10)\n",
        "\n",
        "---\n",
        "**UK late association rules** (11 rules)\n",
        "\n",
        "**Antecedent** entries\n",
        "\n",
        "* 204**42** (All 11)\n",
        "* 445**13** (All 11)\n",
        "* 6286**13** (3 times)\n",
        "* 21255**13** (All 11)\n",
        "* 23403**33** (3 times)\n",
        "* 28932**32** (1 time)\n",
        "\n",
        "**Consequent** entries\n",
        "\n",
        "* 6286**13** (5 times)\n",
        "* 22227**32** (All 11)\n",
        "* 23403**33** (5 times)\n",
        "* 27944**13** (10 times)\n",
        "* 28932**32** (9 time)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTP92PqMymr8"
      },
      "source": [
        "**Entries that show up in antecedent/consequent across samples**\n",
        "\n",
        "**Antecedent**\n",
        "\n",
        "* 14408**33** (Boston, UKE)\n",
        "* 23403**33** (Boston, UKE, UKL)\n",
        "\n",
        "**Consequent**\n",
        "\n",
        "* 3037**13** (Boston, UKE)\n",
        "* 14408**33** (Boston, UKE)\n",
        "* 23403**33** (Boston, UKE, UKL)\n",
        "\n"
      ]
    }
  ]
}