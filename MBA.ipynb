{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MBA",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kxk302/MBA/blob/main/MBA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JDt_5RMdjL7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0bkibi4dy-V"
      },
      "source": [
        "!ls '/content/gdrive/MyDrive/Colab Notebooks/MBA_files'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8BTJgr3VIiP"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "funclass_dict = {\"1\":\"Silent\", \"2\":\"Nonsense\", \"3\":\"Misense\", \"4\":\"None\"}\n",
        "af_dict = {\"1\":\"AF < 0.20\", \"2\": \"0.80 > AF >= 0.20\", \"3\":\"AF >= 0.80\"}\n",
        "\n",
        "def to_str_each(items):\n",
        "  items_str = \"\"\n",
        "  for item in items:\n",
        "    item_str = \"(\" + item[0:-2:1] + \", \" + funclass_dict.get(item[-2:-1:1]) + \", \" + af_dict.get(item[-1]) + \") & \"\n",
        "    items_str += item_str \n",
        "  return items_str[:-3]\n",
        "\n",
        "# Convert series of antecedents/consequents to human readable \n",
        "def to_str(ser):    \n",
        "  # Cast to string\n",
        "  ser = ser.astype(str)  \n",
        "\n",
        "  # Get rid of unnecessary characters prior to list of (position + funclass + af) numbers\n",
        "  ser = ser.str.slice(12,-3,1)  \n",
        "\n",
        "  # Get rid of single quotes\n",
        "  ser = ser.replace('\\'', '', regex=True)\n",
        "\n",
        "  ser = ser.str.split(pat=\",\")\n",
        "\n",
        "  return ser.apply(to_str_each)\n",
        "\n",
        "def add_readable_rules(df_in):\n",
        "  # Empty data frame\n",
        "  if df_in is None or df_in.shape[0] == 0:\n",
        "    return df_in\n",
        "\n",
        "  df = df_in.copy()\n",
        "\n",
        "  antecedents_str = to_str(df['antecedents'])\n",
        "  consequents_str = to_str(df['consequents'])\n",
        "\n",
        "  readable_rule = \"(\" + antecedents_str + \") => (\" + consequents_str + \")\"\n",
        "  df.insert(2,'readable_rule', readable_rule)\n",
        "\n",
        "  return df\n",
        "\n",
        "def filter_on_position_probability(df_in, start_prob=None, end_prob=None):\n",
        "    if df_in is None or df_in.shape[0] == 0:\n",
        "      return df_in\n",
        "\n",
        "    if start_prob is None and end_prob is None:\n",
        "      return df_in\n",
        "\n",
        "    # Only consider rows where probability of Position being present in the Samples is >= start_prob and <= end_prob\n",
        "    num_samples = df_in['Sample'].nunique()\n",
        "    print(\"num_samples: {}\".format(num_samples))\n",
        "\n",
        "    num_positions = df_in['POS'].nunique()\n",
        "    print(\"num_positions: {}\".format(num_positions))\n",
        "   \n",
        "    df = df_in[['Sample', 'POS']].groupby(['POS']).agg(position_prob=('Sample', 'count'))\n",
        "    # Normalize position_prob by dividing it by num_samples. This makes it a proability between 0.0 and 1.0\n",
        "    df['position_prob'] = df['position_prob'] / num_samples   \n",
        "\n",
        "    df_sorted = df.sort_values(by = 'position_prob')\n",
        "    print(df_sorted.head())\n",
        "    print(df_sorted.tail())\n",
        "  \n",
        "    if start_prob is not None:\n",
        "      df = df[df.position_prob >= start_prob]\n",
        "\n",
        "    if end_prob is not None:\n",
        "      df = df[df.position_prob <= end_prob]\n",
        "    \n",
        "    ret_val = pd.merge(df_in, df, on='POS')\n",
        "\n",
        "    df_sorted = ret_val.sort_values(by = 'position_prob')[['POS', 'position_prob']]\n",
        "    print(df_sorted.head())\n",
        "    print(df_sorted.tail())\n",
        "\n",
        "    return ret_val\n",
        "\n",
        "def get_position_probability(df_in, position=None):\n",
        "    if df_in is None or df_in.shape[0] == 0:\n",
        "      return df_in\n",
        "\n",
        "    if position is None:\n",
        "      return df_in\n",
        "\n",
        "    num_samples = df_in['Sample'].nunique()\n",
        "    print(\"num_samples: {}\".format(num_samples))\n",
        "\n",
        "    num_positions = df_in['POS'].nunique()\n",
        "    print(\"num_positions: {}\".format(num_positions))\n",
        "   \n",
        "    df = df_in[['Sample', 'POS']].groupby(['POS']).agg(position_prob=('Sample', 'count'))\n",
        "    # Normalize position_prob by dividing it by num_samples. This makes it a proability between 0.0 and 1.0\n",
        "    df['position_prob'] = df['position_prob'] / num_samples\n",
        "\n",
        "    try:      \n",
        "      return df.loc[position,'position_prob']\n",
        "    except KeyError:\n",
        "      return -1\n",
        "\n",
        "def filter_on_column_values(df_in, start_pos=None, end_pos=None, start_af=None, end_af=None, funclass=[]):  \n",
        "  if df_in is None or df_in.shape[0] == 0:\n",
        "    return df_in\n",
        "\n",
        "  df = df_in.copy()\n",
        "\n",
        "  # Replace \".\" with \"NONE\" in FUNCLASS column. They both represent \"Non-coding\" variant\n",
        "  df[\"FUNCLASS\"] = df[\"FUNCLASS\"].replace('.', 'NONE')\n",
        "\n",
        "  # Filter in_file rows\n",
        "  if start_pos is not None:\n",
        "    df = df[df.POS >= start_pos]    \n",
        "  if end_pos is not None:\n",
        "    df = df[df.POS < end_pos]    \n",
        "  if start_af is not None:\n",
        "    df = df[df.AF >= start_af]    \n",
        "  if end_af is not None:\n",
        "    df = df[df.AF < end_af]    \n",
        "  if len(funclass) > 0:    \n",
        "    df = df[df.FUNCLASS.isin(funclass)]\n",
        "\n",
        "  return df\n",
        "\n",
        "# Create a single integer representing a variant at a specific position with a specific allele frequency\n",
        "# Pivot the data so we have all sample variants on a single line\n",
        "#\n",
        "# Extract rows from in_file where\n",
        "# \n",
        "#    POS >= start_pos & POS <= end_pos\n",
        "#        If start_pos = None: POS <= end_pos\n",
        "#        If end_pos = None: POS >= start_pos \n",
        "#\n",
        "#    AF >= start_af & AF <= end_af\n",
        "#        If start_af = None: AF <= end_af\n",
        "#        If end_af = None: AF >= start_af\n",
        "#\n",
        "#    FUNCLASS in funclass (funclass is a list)      \n",
        "#\n",
        "def preprocess_input_file(df_in):\n",
        "  if df_in is None or df_in.shape[0] == 0:\n",
        "    return df_in\n",
        "  \n",
        "  df = df_in.copy()\n",
        "\n",
        "  # Bucket values in FUNCLASS and AF columns. We do not bucket the values in POS column.\n",
        "\n",
        "  # Replace variants in FUNCLASS column with a distinct numeric value\n",
        "  df.loc[df.FUNCLASS == \"NONE\", \"FUNCLASS\"] = 4\n",
        "  df.loc[df.FUNCLASS == \"MISSENSE\", \"FUNCLASS\"] = 3\n",
        "  df.loc[df.FUNCLASS == \"NONSENSE\", \"FUNCLASS\"] = 2 \n",
        "  df.loc[df.FUNCLASS == \"SILENT\", \"FUNCLASS\"] = 1 \n",
        "\n",
        "  # Replace allele frequency in AF column with a distict numeric value\n",
        "  df.loc[df.AF >= 0.80, \"AF\"] = 3\n",
        "  df.loc[(df.AF >= 0.20) & (df.AF < 0.80), \"AF\"] = 2\n",
        "  df.loc[df.AF < 0.20, \"AF\"] = 1\n",
        "\n",
        "  # Convert AF values to integer\n",
        "  df = df.astype({\"AF\": int}) \n",
        "\n",
        "  # Create a new column called 'Label', which is a string concatentation of POS, FUNCLASS, and AF values. \n",
        "  # The idea is to represent each variant + allele frequency + position as a single integer, to be used in MBA \n",
        "  df[\"Label\"] = df[\"POS\"].astype(str) + df[\"FUNCLASS\"].astype(str) + df[\"AF\"].astype(str)\n",
        "\n",
        "  # We do not need POS, FUNCLASS, and AF columns anymore\n",
        "  df = df[[\"Sample\", \"Label\"]]\n",
        "  \n",
        "  # Add a new column called 'Value', prepopulated with 1\n",
        "  df[\"Value\"] = 1\n",
        "\n",
        "  df = pd.pivot_table(df, index=\"Sample\", columns=\"Label\", values=\"Value\")\n",
        "\n",
        "  # Set all data frame nan (not a number) values to 0\n",
        "  df = df.fillna(0)\n",
        "\n",
        "  # Convert all data framevalues to integer\n",
        "  df = df.astype(int) \n",
        "\n",
        "  return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VubP1ctVUsc"
      },
      "source": [
        "def get_association_rules(in_file, min_support=0.20, min_confidence=0.80, min_lift=1.0, min_conviction=1.0, max_len=None, start_pos=None, end_pos=None, start_af=None, end_af=None, funclass=[], start_prob=None, end_prob=None):\n",
        "  # Read the input file and pick the needed columns\n",
        "  df_in = pd.read_csv(in_file, sep='\\t')[['Sample', 'POS', 'AF', 'FUNCLASS']]\n",
        "\n",
        "  # Filter on position probability\n",
        "  df_pp = filter_on_position_probability(df_in, start_prob, end_prob)\n",
        "\n",
        "  # Filter on column values\n",
        "  df_cv = filter_on_column_values(df_pp, start_pos, end_pos, start_af, end_af, funclass)\n",
        "\n",
        "  # Preprocess the data frame\n",
        "  df = preprocess_input_file(df_cv)\n",
        "\n",
        "  # Get frequent item sets, with support larger than min_support, using Apriori algorithm\n",
        "  frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True, max_len=max_len)\n",
        "\n",
        "  # Get association rules, with lift larger than min_lift  \n",
        "  rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_lift)\n",
        "\n",
        "  # Filter association rules, keeping rules with confidence larger than min_confidence\n",
        "  rules = rules[ (rules['confidence'] >= min_confidence) & (rules['conviction'] >= min_conviction) ]\n",
        "\n",
        "  return rules"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxoxfSG9fRA3"
      },
      "source": [
        "pd.set_option('max_columns', 10, 'display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "bos_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/bos_by_sample.tsv.gz\", min_support=0.223, min_confidence=0.905, min_lift=2.863, min_conviction=7.0)\n",
        "num_rules = bos_rules.shape[0]\n",
        "print('Boston dataset association rules: ')\n",
        "bos_rules = add_readable_rules(bos_rules)\n",
        "print(bos_rules.head(num_rules))\n",
        "print('\\n\\n')\n",
        "# bos_rules.to_csv('/content/gdrive/MyDrive/Colab Notebooks/MBA_files/bos_0223_0905_2863_7000.csv', sep=',')\n",
        "\n",
        "uke_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/cog_20200917_by_sample.tsv.gz\", min_support=0.21, min_confidence=0.91, min_lift=2.5, min_conviction=7.0)\n",
        "num_rules = uke_rules.shape[0]\n",
        "print('UK early dataset association rules: ')\n",
        "uke_rules = add_readable_rules(uke_rules)\n",
        "print(uke_rules.head(num_rules))\n",
        "print('\\n\\n')\n",
        "# uke_rules.to_csv('/content/gdrive/MyDrive/Colab Notebooks/MBA_files/uke_0210_0910_2500_7000.csv', sep=',')\n",
        "\n",
        "ukl_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/cog_20201120_by_sample.tsv.gz\", min_support=0.203, min_confidence=0.926, min_lift=2.03, min_conviction=7.0)\n",
        "num_rules = ukl_rules.shape[0]\n",
        "print('Uk late dataset association rules: ')\n",
        "ukl_rules = add_readable_rules(ukl_rules)\n",
        "print(ukl_rules.head(num_rules))\n",
        "print('\\n\\n')\n",
        "# ukl_rules.to_csv('/content/gdrive/MyDrive/Colab Notebooks/MBA_files/ukl_0203_0926_2030_7000.csv', sep=',')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy3YlHqEyPGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ea261e-57a3-49f6-b82b-3fe9457d656e"
      },
      "source": [
        "# Milad \n",
        "pd.set_option('max_columns', 10, 'display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "bos_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/bos_by_sample.tsv.gz\", min_support=0.005, min_confidence=0.05, min_lift=1.00, min_conviction=1.0, max_len=6, start_pos=21563, end_pos=25384, start_af=0.05, end_af=0.25, funclass=[\"MISSENSE\", \"SILENT\"])\n",
        "num_rules = bos_rules.shape[0]\n",
        "print('Boston dataset association rules: ')\n",
        "bos_rules = add_readable_rules(bos_rules)\n",
        "print(bos_rules.head(num_rules))\n",
        "print('\\n\\n')\n",
        "# bos_rules.to_csv('/content/gdrive/MyDrive/Colab Notebooks/MBA_files/bos_0223_0905_2863_7000.csv', sep=',')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Boston dataset association rules: \n",
            "  antecedents consequents                                                   readable_rule  antecedent support  consequent support   support  confidence      lift  leverage  conviction\n",
            "1   (2165831)   (2355431)  ((21658, Misense, AF < 0.20)) => ((23554, Misense, AF < 0.20))            0.013216            0.462555  0.008811    0.666667  1.441270  0.002698    1.612335\n",
            "2   (2194931)   (2355431)  ((21949, Misense, AF < 0.20)) => ((23554, Misense, AF < 0.20))            0.035242            0.462555  0.017621    0.500000  1.080952  0.001320    1.074890\n",
            "4   (2308611)   (2365231)   ((23086, Silent, AF < 0.20)) => ((23652, Misense, AF < 0.20))            0.039648            0.052863  0.008811    0.222222  4.203704  0.006715    1.217747\n",
            "5   (2365231)   (2308611)   ((23652, Misense, AF < 0.20)) => ((23086, Silent, AF < 0.20))            0.052863            0.039648  0.008811    0.166667  4.203704  0.006715    1.152423\n",
            "6   (2308611)   (2496631)   ((23086, Silent, AF < 0.20)) => ((24966, Misense, AF < 0.20))            0.039648            0.079295  0.008811    0.222222  2.802469  0.005667    1.183763\n",
            "7   (2496631)   (2308611)   ((24966, Misense, AF < 0.20)) => ((23086, Silent, AF < 0.20))            0.079295            0.039648  0.008811    0.111111  2.802469  0.005667    1.080396\n",
            "8   (2496631)   (2494231)  ((24966, Misense, AF < 0.20)) => ((24942, Misense, AF < 0.20))            0.079295            0.193833  0.026432    0.333333  1.719697  0.011062    1.209251\n",
            "9   (2494231)   (2496631)  ((24942, Misense, AF < 0.20)) => ((24966, Misense, AF < 0.20))            0.193833            0.079295  0.026432    0.136364  1.719697  0.011062    1.066079\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5erF_k0uKLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28870384-1141-4676-b2bb-7b226225320a"
      },
      "source": [
        "# Anton\n",
        "pd.set_option('max_columns', 10, 'display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "bos_rules = get_association_rules(in_file=\"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/bos_by_sample.tsv.gz\", min_support=0.050, min_confidence=0.800, min_lift=1.0, min_conviction=1.0, max_len=6, end_af=0.80, start_prob=0.000, end_prob=0.250, funclass=[\"MISSENSE\", \"SILENT\"])\n",
        "num_rules = bos_rules.shape[0]\n",
        "print('Number of rules: {}'.format(num_rules))\n",
        "print('Boston dataset association rules: ')\n",
        "bos_rules = add_readable_rules(bos_rules)\n",
        "print(bos_rules.head(num_rules))\n",
        "print('\\n\\n')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_samples: 639\n",
            "num_positions: 1013\n",
            "       position_prob\n",
            "POS                 \n",
            "28893       0.001565\n",
            "18546       0.001565\n",
            "28647       0.001565\n",
            "18636       0.001565\n",
            "18714       0.001565\n",
            "       position_prob\n",
            "POS                 \n",
            "25563       0.852895\n",
            "241         0.948357\n",
            "23403       0.949922\n",
            "14408       0.951487\n",
            "3037        0.951487\n",
            "        POS  position_prob\n",
            "4778   5431       0.001565\n",
            "4056  24069       0.001565\n",
            "4052  25572       0.001565\n",
            "4051   7479       0.001565\n",
            "4050  21058       0.001565\n",
            "       POS  position_prob\n",
            "782  26233       0.214397\n",
            "781  26233       0.214397\n",
            "780  26233       0.214397\n",
            "786  26233       0.214397\n",
            "693  26233       0.214397\n",
            "Number of rules: 23\n",
            "Boston dataset association rules: \n",
            "            antecedents consequents                                                                                readable_rule  antecedent support  consequent support   support  confidence       lift  leverage  conviction\n",
            "24             (953511)   (1375531)                                 ((9535, Silent, AF < 0.20)) => ((13755, Misense, AF < 0.20))            0.070611            0.101145  0.059160    0.837838   8.283529  0.052018    5.542939\n",
            "27            (1568531)   (1568231)                               ((15685, Misense, AF < 0.20)) => ((15682, Misense, AF < 0.20))            0.169847            0.251908  0.166031    0.977528   3.880490  0.123245   33.290076\n",
            "40            (2071631)   (2355431)                               ((20716, Misense, AF < 0.20)) => ((23554, Misense, AF < 0.20))            0.070611            0.200382  0.059160    0.837838   4.181210  0.045011    4.930980\n",
            "42            (2071631)   (2612411)                                ((20716, Misense, AF < 0.20)) => ((26124, Silent, AF < 0.20))            0.070611            0.146947  0.057252    0.810811   5.517726  0.046876    4.508997\n",
            "48             (953511)   (2071631)                                 ((9535, Silent, AF < 0.20)) => ((20716, Misense, AF < 0.20))            0.070611            0.070611  0.059160    0.837838  11.865595  0.054174    5.731234\n",
            "49            (2071631)    (953511)                                 ((20716, Misense, AF < 0.20)) => ((9535, Silent, AF < 0.20))            0.070611            0.070611  0.059160    0.837838  11.865595  0.054174    5.731234\n",
            "58             (953511)   (2355431)                                 ((9535, Silent, AF < 0.20)) => ((23554, Misense, AF < 0.20))            0.070611            0.200382  0.057252    0.810811   4.046332  0.043103    4.226554\n",
            "60            (2643331)   (2612411)                                ((26433, Misense, AF < 0.20)) => ((26124, Silent, AF < 0.20))            0.064885            0.146947  0.055344    0.852941   5.804431  0.045809    5.800763\n",
            "66             (953511)   (2612411)                                  ((9535, Silent, AF < 0.20)) => ((26124, Silent, AF < 0.20))            0.070611            0.146947  0.057252    0.810811   5.517726  0.046876    4.508997\n",
            "69            (2643331)    (750731)                                ((26433, Misense, AF < 0.20)) => ((7507, Misense, AF < 0.20))            0.064885            0.230916  0.059160    0.911765   3.948469  0.044177    8.716285\n",
            "72             (576531)    (576631)                                 ((5765, Misense, AF < 0.20)) => ((5766, Misense, AF < 0.20))            0.087786            0.108779  0.083969    0.956522   8.793288  0.074420   20.498092\n",
            "76             (953511)    (660411)                                   ((9535, Silent, AF < 0.20)) => ((6604, Silent, AF < 0.20))            0.070611            0.103053  0.059160    0.837838   8.130130  0.051884    5.531170\n",
            "94    (750731, 1375531)   (2612411)  ((7507, Misense, AF < 0.20) & ( 13755, Misense, AF < 0.20)) => ((26124, Silent, AF < 0.20))            0.074427            0.146947  0.064885    0.871795   5.932734  0.053949    6.653817\n",
            "96   (1375531, 2612411)    (750731)  ((13755, Misense, AF < 0.20) & ( 26124, Silent, AF < 0.20)) => ((7507, Misense, AF < 0.20))            0.072519            0.230916  0.064885    0.894737   3.874728  0.048140    7.306298\n",
            "100   (953511, 2071631)   (2612411)   ((9535, Silent, AF < 0.20) & ( 20716, Misense, AF < 0.20)) => ((26124, Silent, AF < 0.20))            0.059160            0.146947  0.051527    0.870968   5.927105  0.042833    6.611164\n",
            "101   (953511, 2612411)   (2071631)   ((9535, Silent, AF < 0.20) & ( 26124, Silent, AF < 0.20)) => ((20716, Misense, AF < 0.20))            0.057252            0.070611  0.051527    0.900000  12.745946  0.047484    9.293893\n",
            "102  (2071631, 2612411)    (953511)   ((20716, Misense, AF < 0.20) & ( 26124, Silent, AF < 0.20)) => ((9535, Silent, AF < 0.20))            0.057252            0.070611  0.051527    0.900000  12.745946  0.047484    9.293893\n",
            "118   (750731, 2643331)   (2612411)  ((7507, Misense, AF < 0.20) & ( 26433, Misense, AF < 0.20)) => ((26124, Silent, AF < 0.20))            0.059160            0.146947  0.051527    0.870968   5.927105  0.042833    6.611164\n",
            "120  (2643331, 2612411)    (750731)  ((26433, Misense, AF < 0.20) & ( 26124, Silent, AF < 0.20)) => ((7507, Misense, AF < 0.20))            0.055344            0.230916  0.051527    0.931034   4.031918  0.038747   11.151718\n",
            "126   (660411, 2612411)    (750731)    ((6604, Silent, AF < 0.20) & ( 26124, Silent, AF < 0.20)) => ((7507, Misense, AF < 0.20))            0.062977            0.230916  0.051527    0.818182   3.543201  0.036984    4.229962\n",
            "130    (953511, 660411)   (2612411)     ((9535, Silent, AF < 0.20) & ( 6604, Silent, AF < 0.20)) => ((26124, Silent, AF < 0.20))            0.059160            0.146947  0.051527    0.870968   5.927105  0.042833    6.611164\n",
            "131   (953511, 2612411)    (660411)     ((9535, Silent, AF < 0.20) & ( 26124, Silent, AF < 0.20)) => ((6604, Silent, AF < 0.20))            0.057252            0.103053  0.051527    0.900000   8.733333  0.045627    8.969466\n",
            "132   (660411, 2612411)    (953511)     ((6604, Silent, AF < 0.20) & ( 26124, Silent, AF < 0.20)) => ((9535, Silent, AF < 0.20))            0.062977            0.070611  0.051527    0.818182  11.587224  0.047080    5.111641\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEa5yn9JFJDI"
      },
      "source": [
        "# Test get_position_probability()\n",
        "\n",
        "pd.set_option('max_columns', 10, 'display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Read the input file and pick the needed columns\n",
        "in_file = \"https://github.com/galaxyproject/SARS-CoV-2/raw/master/data/var/bos_by_sample.tsv.gz\"\n",
        "df_in = pd.read_csv(in_file, sep='\\t')[['Sample', 'POS', 'AF', 'FUNCLASS']]\n",
        "\n",
        "position=26542\n",
        "position_prob = get_position_probability(df_in, position=position)\n",
        "print(\"position: {}, position_prob: {:.4f}\".format(position, position_prob))\n",
        "\n",
        "position=26542\n",
        "position_prob = get_position_probability(df_in, position=position)\n",
        "print(\"position: {}, position_prob: {:.4f}\".format(position, position_prob))\n",
        "\n",
        "position=23403\n",
        "position_prob = get_position_probability(df_in, position=position)\n",
        "print(\"position: {}, position_prob: {:.4f}\".format(position, position_prob))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ASKXDBeOsr"
      },
      "source": [
        "---\n",
        "**MBA parameter**s \n",
        "\n",
        "1.   **bos_rules**: *support*=0.223, *confidence*=0.905, *lift*=2.863, *conviction*=7.000\n",
        "2.   **uke_rules**: *support*=0.210, *confidence*=0.910, *lift*=2.500, conviction *italicized text*=7.000\n",
        "3.   **ukl_rules**: *support*=0.203, *confidence*=0.926, *lift*=2.030, *conviction*=7.000\n",
        "---\n",
        "The last digit of an entry is Allele Frequency (**AF**)\n",
        "\n",
        "*   **3**: $>=$ 0.80    \n",
        "*   **2**: $>=$ 0.20 and $<$ 0.80\n",
        "*   **1**: $<$ 0.20\n",
        "---\n",
        "The digit before the last is **Funclass**\n",
        "\n",
        "*  **4**: None\n",
        "*  **3**: Missense\n",
        "*  **2**: Nonsense\n",
        "*  **1**: Silent\n",
        "---\n",
        "**Boston association rules** (12 rules)\n",
        "\n",
        "**Antecedent** entries\n",
        "\n",
        "* 3037**13**  (5 times)\n",
        "* 14408**33** (5 times)\n",
        "* 23403**33** (5 times)\n",
        "* 26542**31** (All 12)\n",
        "\n",
        "**Consequent** entries\n",
        "\n",
        "* 3037**13** (5 times)\n",
        "* 14408**33** (5 times)\n",
        "* 23403**33** (5 times)\n",
        "* 26545**31** (All 12)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XszXqioqokmE"
      },
      "source": [
        "---\n",
        "**UK early association rules** (10 rules)\n",
        "\n",
        "**Antecedent** entries\n",
        "\n",
        "* 241**43**   (9 times)\n",
        "* 14408**33** (3 times)\n",
        "* 23403**33** (4 times)\n",
        "* 28881**32** (All 10)\n",
        "\n",
        "**Consequent** entries\n",
        "\n",
        "* 3037**12**  (All 10)\n",
        "* 14408**33** (3 times)\n",
        "* 23403**33** (3 times)\n",
        "* 28883**33** (All 10)\n",
        "\n",
        "---\n",
        "**UK late association rules** (11 rules)\n",
        "\n",
        "**Antecedent** entries\n",
        "\n",
        "* 204**42** (All 11)\n",
        "* 445**13** (All 11)\n",
        "* 6286**13** (3 times)\n",
        "* 21255**13** (All 11)\n",
        "* 23403**33** (3 times)\n",
        "* 28932**32** (1 time)\n",
        "\n",
        "**Consequent** entries\n",
        "\n",
        "* 6286**13** (5 times)\n",
        "* 22227**32** (All 11)\n",
        "* 23403**33** (5 times)\n",
        "* 27944**13** (10 times)\n",
        "* 28932**32** (9 time)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTP92PqMymr8"
      },
      "source": [
        "**Entries that show up in antecedent/consequent across samples**\n",
        "\n",
        "**Antecedent**\n",
        "\n",
        "* 14408**33** (Boston, UKE)\n",
        "* 23403**33** (Boston, UKE, UKL)\n",
        "\n",
        "**Consequent**\n",
        "\n",
        "* 3037**13** (Boston, UKE)\n",
        "* 14408**33** (Boston, UKE)\n",
        "* 23403**33** (Boston, UKE, UKL)\n",
        "\n"
      ]
    }
  ]
}